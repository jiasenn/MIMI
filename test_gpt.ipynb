{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refer to this for installation https://github.com/abetlen/llama-cpp-python#installation-with-openblas--cublas--clblast--metal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (0.8.53.post3)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index) (2.0.22)\n",
      "Requirement already satisfied: aiostream<0.6.0,>=0.5.2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.5.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.5.14)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (1.2.14)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (2023.10.0)\n",
      "Requirement already satisfied: langchain>=0.0.303 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.0.324)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (1.5.8)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (1.26.1)\n",
      "Requirement already satisfied: openai>=0.26.4 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (2.1.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (4.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.9.0)\n",
      "Requirement already satisfied: urllib3<2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (1.26.18)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->llama_index) (3.20.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from deprecated>=1.2.9.3->llama_index) (1.15.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (4.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (0.0.52)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (2.31.0)\n",
      "Requirement already satisfied: click in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (4.66.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama_index) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama_index) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from pandas->llama_index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from pandas->llama_index) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from pandas->llama_index) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (1.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.303->llama_index) (2.4)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->llama_index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.303->llama_index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.303->llama_index) (2.10.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama_index) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.303->llama_index) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from click->nltk<4.0.0,>=3.8.1->llama_index) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (0.2.11)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama-cpp-python) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama-cpp-python) (1.26.1)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_index\n",
    "%pip install llama-cpp-python\n",
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)  # Change INFO to DEBUG if you want more extensive logging\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    model_url=\"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q5_K_M.gguf\",\n",
    "    \n",
    "    # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "    model_path=None,\n",
    "    \n",
    "    temperature=0.0,\n",
    "    max_new_tokens=1024,\n",
    "    \n",
    "    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "    context_window=3900,  # note, this sets n_ctx in the model_kwargs below, so you don't need to pass it there.\n",
    "    \n",
    "    # kwargs to pass to __call__()\n",
    "    generate_kwargs={},\n",
    "    \n",
    "    # kwargs to pass to __init__()\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": 4}, # I need to play with this and see if it actually helps\n",
    "    \n",
    "    # transform inputs into Llama2 format\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Downloads\\Github\\MIMI\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  0.003994 seconds\n",
      "      |_chunking ->  0.003994 seconds\n",
      "    |_embedding ->  0.903892 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# Create an index of your documents\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "\n",
    "storage_directory = \"./storage\"\n",
    "\n",
    "documents = SimpleDirectoryReader('./testdata').load_data()\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=1024,\n",
    "                                               embed_model=\"local\",\n",
    "                                               callback_manager=callback_manager)\n",
    "\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "# Persist the index to disk\n",
    "index.storage_context.persist(persist_dir=storage_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# Now you can load the index from disk when needed, and not rebuild it each time.\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "# transcript_directory = \"transcripts/ancient-aliens-official\"\n",
    "storage_directory = \"./storage\"\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=1024,\n",
    "                                               embed_model=\"local\",\n",
    "                                               callback_manager=callback_manager)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=storage_directory)\n",
    "index = load_index_from_storage(storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_query ->  305.296014 seconds\n",
      "      |_retrieve ->  0.027924 seconds\n",
      "        |_embedding ->  0.02593 seconds\n",
      "      |_synthesize ->  305.267092 seconds\n",
      "        |_templating ->  0.000997 seconds\n",
      "        |_llm ->  305.240215 seconds\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>  Based on the provided context, here is a summary of Facebook's LLaMa in three sentences:\n",
       "\n",
       "Facebook has publicly released LLaMa, a state-of-the-art foundational large language model designed to help researchers advance their work in this subfield of AI. The model is trained on a large set of unlabeled data and is ideal for fine-tuning for a variety of tasks. With the release of LLaMa, Facebook aims to democratize access to large-scale language models and promote responsible AI practices.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query your index!\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.prompts import PromptTemplate\n",
    "\n",
    "query_engine = index.as_query_engine(service_context=service_context,\n",
    "                                     similarity_top_k=3)\n",
    "\n",
    "# response = query_engine.query(\"What do you think of Facebook's LLaMa?\")\n",
    "# print(response)\n",
    "\n",
    "# query = \"What is the Alien nuclear agenda? \\n\\n\" \\\n",
    "#         \"Please summarize the information into 3 detailed paragraphs, something suitable for a blog post.\"\n",
    "\n",
    "query = \"What do you think of Facebook's LLaMa? \\n\\n\" \\\n",
    "        \"Please summarize the information into 3 sentences, something suitable for a tweet.\"\n",
    "\n",
    "response = query_engine.query(query)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
