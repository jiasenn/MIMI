{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refer to this for installation https://github.com/abetlen/llama-cpp-python#installation-with-openblas--cublas--clblast--metal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (0.8.53.post3)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index) (2.0.22)\n",
      "Requirement already satisfied: aiostream<0.6.0,>=0.5.2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.5.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.5.14)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (1.2.14)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (2023.10.0)\n",
      "Requirement already satisfied: langchain>=0.0.303 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.0.324)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (1.5.8)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (1.26.1)\n",
      "Requirement already satisfied: openai>=0.26.4 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (2.1.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (4.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (0.9.0)\n",
      "Requirement already satisfied: urllib3<2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama_index) (1.26.18)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->llama_index) (3.20.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from deprecated>=1.2.9.3->llama_index) (1.15.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (4.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (0.0.52)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from langchain>=0.0.303->llama_index) (2.31.0)\n",
      "Requirement already satisfied: click in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (4.66.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama_index) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama_index) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from pandas->llama_index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from pandas->llama_index) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from pandas->llama_index) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (1.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.303->llama_index) (2.4)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->llama_index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.303->llama_index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.303->llama_index) (2.10.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama_index) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.303->llama_index) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from click->nltk<4.0.0,>=3.8.1->llama_index) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (0.2.11)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama-cpp-python) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama-cpp-python) (1.26.1)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.1.0-cp310-cp310-win_amd64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from torch) (4.8.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\downloads\\github\\mimi\\.venv\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-2.1.3-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached torch-2.1.0-cp310-cp310-win_amd64.whl (192.3 MB)\n",
      "Using cached networkx-3.2-py3-none-any.whl (1.6 MB)\n",
      "Using cached MarkupSafe-2.1.3-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.3 jinja2-3.1.2 mpmath-1.3.0 networkx-3.2 sympy-1.12 torch-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_index\n",
    "%pip install llama-cpp-python\n",
    "%pip install transformers\n",
    "%pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)  # Change INFO to DEBUG if you want more extensive logging\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    model_url=\"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q5_K_M.gguf\",\n",
    "    \n",
    "    # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "    model_path=None,\n",
    "    \n",
    "    temperature=0.0,\n",
    "    max_new_tokens=1024,\n",
    "    \n",
    "    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "    context_window=3900,  # note, this sets n_ctx in the model_kwargs below, so you don't need to pass it there.\n",
    "    \n",
    "    # kwargs to pass to __call__()\n",
    "    generate_kwargs={},\n",
    "    \n",
    "    # kwargs to pass to __init__()\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": 4}, # I need to play with this and see if it actually helps\n",
    "    \n",
    "    # transform inputs into Llama2 format\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Downloads\\Github\\MIMI\\test_gpt.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Downloads/Github/MIMI/test_gpt.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m storage_directory \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./storage\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Downloads/Github/MIMI/test_gpt.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m documents \u001b[39m=\u001b[39m SimpleDirectoryReader(\u001b[39m'\u001b[39m\u001b[39m./testdata\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mload_data()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Downloads/Github/MIMI/test_gpt.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m service_context \u001b[39m=\u001b[39m ServiceContext\u001b[39m.\u001b[39;49mfrom_defaults(llm\u001b[39m=\u001b[39;49mllm, chunk_size\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Downloads/Github/MIMI/test_gpt.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                                embed_model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlocal\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Downloads/Github/MIMI/test_gpt.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                                callback_manager\u001b[39m=\u001b[39;49mcallback_manager)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Downloads/Github/MIMI/test_gpt.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m index \u001b[39m=\u001b[39m VectorStoreIndex\u001b[39m.\u001b[39mfrom_documents(documents, service_context\u001b[39m=\u001b[39mservice_context)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Downloads/Github/MIMI/test_gpt.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Persist the index to disk\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Downloads\\Github\\MIMI\\.venv\\lib\\site-packages\\llama_index\\indices\\service_context.py:163\u001b[0m, in \u001b[0;36mServiceContext.from_defaults\u001b[1;34m(cls, llm_predictor, llm, prompt_helper, embed_model, node_parser, llama_logger, callback_manager, system_prompt, query_wrapper_prompt, chunk_size, chunk_overlap, context_window, num_output, chunk_size_limit)\u001b[0m\n\u001b[0;32m    160\u001b[0m         llm_predictor\u001b[39m.\u001b[39mquery_wrapper_prompt \u001b[39m=\u001b[39m query_wrapper_prompt\n\u001b[0;32m    162\u001b[0m \u001b[39m# NOTE: the embed_model isn't used in all indices\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m embed_model \u001b[39m=\u001b[39m resolve_embed_model(embed_model)\n\u001b[0;32m    164\u001b[0m embed_model\u001b[39m.\u001b[39mcallback_manager \u001b[39m=\u001b[39m callback_manager\n\u001b[0;32m    166\u001b[0m prompt_helper \u001b[39m=\u001b[39m prompt_helper \u001b[39mor\u001b[39;00m _get_default_prompt_helper(\n\u001b[0;32m    167\u001b[0m     llm_metadata\u001b[39m=\u001b[39mllm_predictor\u001b[39m.\u001b[39mmetadata,\n\u001b[0;32m    168\u001b[0m     context_window\u001b[39m=\u001b[39mcontext_window,\n\u001b[0;32m    169\u001b[0m     num_output\u001b[39m=\u001b[39mnum_output,\n\u001b[0;32m    170\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Downloads\\Github\\MIMI\\.venv\\lib\\site-packages\\llama_index\\embeddings\\utils.py:70\u001b[0m, in \u001b[0;36mresolve_embed_model\u001b[1;34m(embed_model)\u001b[0m\n\u001b[0;32m     66\u001b[0m         embed_model \u001b[39m=\u001b[39m InstructorEmbedding(\n\u001b[0;32m     67\u001b[0m             model_name\u001b[39m=\u001b[39mmodel_name, cache_folder\u001b[39m=\u001b[39mcache_folder\n\u001b[0;32m     68\u001b[0m         )\n\u001b[0;32m     69\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m         embed_model \u001b[39m=\u001b[39m HuggingFaceEmbedding(\n\u001b[0;32m     71\u001b[0m             model_name\u001b[39m=\u001b[39;49mmodel_name, cache_folder\u001b[39m=\u001b[39;49mcache_folder\n\u001b[0;32m     72\u001b[0m         )\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(embed_model, LCEmbeddings):\n\u001b[0;32m     75\u001b[0m     embed_model \u001b[39m=\u001b[39m LangchainEmbedding(embed_model)\n",
      "File \u001b[1;32mc:\\Users\\User\\Downloads\\Github\\MIMI\\.venv\\lib\\site-packages\\llama_index\\embeddings\\huggingface.py:71\u001b[0m, in \u001b[0;36mHuggingFaceEmbedding.__init__\u001b[1;34m(self, model_name, tokenizer_name, pooling, max_length, query_instruction, text_instruction, normalize, model, tokenizer, embed_batch_size, cache_folder, trust_remote_code, device, callback_manager)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     model_name \u001b[39m=\u001b[39m model_name \u001b[39mor\u001b[39;00m DEFAULT_HUGGINGFACE_EMBEDDING_MODEL\n\u001b[1;32m---> 71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m     72\u001b[0m         model_name, cache_dir\u001b[39m=\u001b[39mcache_folder, trust_remote_code\u001b[39m=\u001b[39mtrust_remote_code\n\u001b[0;32m     73\u001b[0m     )\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device)\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m model\n",
      "File \u001b[1;32mc:\\Users\\User\\Downloads\\Github\\MIMI\\.venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:1222\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1221\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1222\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[1;32mc:\\Users\\User\\Downloads\\Github\\MIMI\\.venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:1210\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1208\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m-> 1210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "# Create an index of your documents\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "\n",
    "storage_directory = \"./storage\"\n",
    "\n",
    "documents = SimpleDirectoryReader('./testdata').load_data()\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=1024,\n",
    "                                               embed_model=\"local\",\n",
    "                                               callback_manager=callback_manager)\n",
    "\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "# Persist the index to disk\n",
    "index.storage_context.persist(persist_dir=storage_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
